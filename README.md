# WhisperX + pyannote.audio í™”ìë¶„ë¦¬ ì „ì‚¬ API ì„œë²„

WhisperXì™€ pyannote.audioë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ í™”ìë¶„ë¦¬ ì „ì‚¬ REST API ì„œë²„ì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

- **ê³ ì† ìŒì„± ì¸ì‹**: WhisperXë¡œ 70ë°° ì‹¤ì‹œê°„ ì†ë„ ì „ì‚¬
- **í™”ìë¶„ë¦¬**: pyannote.audioë¡œ í™”ìë³„ êµ¬ë¶„
- **ì •í™•í•œ íƒ€ì„ìŠ¤íƒ¬í”„**: ë‹¨ì–´/ë¬¸ì¥ ë ˆë²¨ íƒ€ì„ìŠ¤íƒ¬í”„
- **ë‹¤êµ­ì–´ ì§€ì›**: ìë™ ì–¸ì–´ ê°ì§€ ë° ë‹¤êµ­ì–´ ì „ì‚¬
- **GPU ê°€ì†**: CUDA ì§€ì›ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬
- **Docker ì§€ì›**: ê°„í¸í•œ ë°°í¬ ë° ì‹¤í–‰

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- Python 3.10+
- CUDA 11.8+ (GPU ì‚¬ìš© ì‹œ)
- Docker & Docker Compose (ê¶Œì¥)

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **GPU**: NVIDIA GPU (8GB+ VRAM ê¶Œì¥)
- **CPU**: 8ì½”ì–´ ì´ìƒ (CPU ì „ìš© ëª¨ë“œ)
- **RAM**: 16GB ì´ìƒ
- **ì €ì¥ê³µê°„**: 20GB ì´ìƒ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì‹¤í–‰

### 1. ì €ì¥ì†Œ í´ë¡ 
```bash
git clone <repository-url>
cd whisperx-api
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
```bash
cp env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ HuggingFace í† í° ì„¤ì •
```

### 3. HuggingFace í† í° ì„¤ì •
1. [HuggingFace](https://huggingface.co/) ê³„ì • ìƒì„±
2. [Access Tokens](https://huggingface.co/settings/tokens)ì—ì„œ í† í° ìƒì„±
3. `.env` íŒŒì¼ì— í† í° ì„¤ì •:
```bash
HUGGINGFACE_TOKEN=your_token_here
```

### 4. Dockerë¡œ ì‹¤í–‰ (ê¶Œì¥)

#### GPU ë²„ì „
```bash
# GPU ì§€ì› Docker Compose ì‹¤í–‰
docker-compose up -d
```

#### CPU ì „ìš© ë²„ì „
```bash
# CPU ì „ìš© Docker Compose ì‹¤í–‰
docker-compose -f docker-compose.cpu.yml up -d
```

### 5. ë¡œì»¬ ê°œë°œ í™˜ê²½ ì‹¤í–‰

#### ê°€ìƒí™˜ê²½ ìƒì„±
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ë˜ëŠ”
venv\Scripts\activate  # Windows
```

#### ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

#### ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
```bash
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“– API ì‚¬ìš©ë²•

### ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸

#### 1. í—¬ìŠ¤ ì²´í¬
```bash
GET /health
```

#### 2. ì˜¤ë””ì˜¤ ì „ì‚¬
```bash
POST /v1/audio/transcribe
Content-Type: multipart/form-data

# íŒŒì¼ ì—…ë¡œë“œ
curl -X POST http://localhost:8000/v1/audio/transcribe \
  -F "file=@audio.mp3"
```

#### 3. ëª¨ë¸ ì •ë³´ ì¡°íšŒ
```bash
GET /v1/models/info
```

### ì‘ë‹µ í˜•ì‹

#### ì„±ê³µ ì‘ë‹µ
```json
{
  "status": "success",
  "transcription": [
    {
      "speaker": "SPEAKER_00",
      "start": 0.5,
      "end": 3.2,
      "text": "ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
      "confidence": 0.95
    },
    {
      "speaker": "SPEAKER_01",
      "start": 3.5,
      "end": 6.1,
      "text": "ë„¤, ì¢‹ìŠµë‹ˆë‹¤. ì¤€ë¹„ê°€ ë‹¤ ë˜ì—ˆìŠµë‹ˆë‹¤.",
      "confidence": 0.92
    }
  ],
  "processing_time": 15.2,
  "language": "ko",
  "total_duration": 120.5,
  "speakers_count": 2
}
```

#### ì—ëŸ¬ ì‘ë‹µ
```json
{
  "status": "error",
  "error": "íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤",
  "detail": "ìµœëŒ€ 500MBê¹Œì§€ ì§€ì›ë©ë‹ˆë‹¤",
  "timestamp": "2024-01-01T12:00:00Z"
}
```

## ğŸ”§ ì„¤ì • ì˜µì…˜

### í™˜ê²½ ë³€ìˆ˜

| ë³€ìˆ˜ëª… | ê¸°ë³¸ê°’ | ì„¤ëª… |
|--------|--------|------|
| `HOST` | `0.0.0.0` | ì„œë²„ í˜¸ìŠ¤íŠ¸ |
| `PORT` | `8000` | ì„œë²„ í¬íŠ¸ |
| `WHISPER_MODEL` | `large-v2` | Whisper ëª¨ë¸ |
| `DEVICE` | `cuda` | ë””ë°”ì´ìŠ¤ (cuda/cpu) |
| `COMPUTE_TYPE` | `float16` | ê³„ì‚° íƒ€ì… |
| `LANGUAGE` | `ko` | ì–¸ì–´ ì„¤ì • |
| `MAX_FILE_SIZE` | `500` | ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB) |
| `HUGGINGFACE_TOKEN` | - | HuggingFace í† í° |

### ì§€ì› íŒŒì¼ í˜•ì‹
- **ì˜¤ë””ì˜¤**: MP3, WAV, FLAC, AAC, OGG, WMA
- **ë¹„ë””ì˜¤**: MP4, AVI, MOV, MKV

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### GPU ì‚¬ìš© ì‹œ
```bash
# CUDA ì„¤ì •
export CUDA_VISIBLE_DEVICES=0
export DEVICE=cuda
export COMPUTE_TYPE=float16
```

### CPU ì‚¬ìš© ì‹œ
```bash
# CPU ìµœì í™” ì„¤ì •
export DEVICE=cpu
export COMPUTE_TYPE=int8
```

### ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# ëª¨ë¸ ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
export MODEL_CACHE_DIR=/app/models
```

## ğŸ”— Spring Boot ì—°ë™

Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ ì—°ë™ ì˜ˆì‹œëŠ” `examples/spring-boot/` ë””ë ‰í† ë¦¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### ì£¼ìš” í´ë˜ìŠ¤
- `WhisperXClient`: API í´ë¼ì´ì–¸íŠ¸
- `TranscriptionController`: REST ì»¨íŠ¸ë¡¤ëŸ¬
- `WhisperXConfig`: ì„¤ì • í´ë˜ìŠ¤

### ì‚¬ìš© ì˜ˆì‹œ
```java
@Autowired
private WhisperXClient whisperXClient;

public TranscriptionResponse transcribe(MultipartFile file) {
    return whisperXClient.transcribeAudio(file);
}
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. HuggingFace í† í° ì˜¤ë¥˜
```
Error: HuggingFace token is required
```
**í•´ê²°ë°©ë²•**: `.env` íŒŒì¼ì— ì˜¬ë°”ë¥¸ í† í° ì„¤ì •

#### 2. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```
Error: CUDA out of memory
```
**í•´ê²°ë°©ë²•**: 
- ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© (`medium` ë˜ëŠ” `small`)
- `COMPUTE_TYPE=int8` ì„¤ì •
- CPU ëª¨ë“œ ì‚¬ìš©

#### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```
Error: Model download failed
```
**í•´ê²°ë°©ë²•**:
- ì¸í„°ë„· ì—°ê²° í™•ì¸
- HuggingFace í† í° í™•ì¸
- ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

### ë¡œê·¸ í™•ì¸
```bash
# Docker ë¡œê·¸ í™•ì¸
docker-compose logs -f whisperx-api

# ë¡œì»¬ ì‹¤í–‰ ì‹œ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
export LOG_LEVEL=DEBUG
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### í—¬ìŠ¤ ì²´í¬
```bash
curl http://localhost:8000/health
```

### ëª¨ë¸ ìƒíƒœ í™•ì¸
```bash
curl http://localhost:8000/v1/models/info
```

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ™ ê°ì‚¬ì˜ ë§

- [WhisperX](https://github.com/m-bain/whisperX) - ê³ ì† ìŒì„± ì¸ì‹
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - í™”ìë¶„ë¦¬
- [FastAPI](https://fastapi.tiangolo.com/) - ì›¹ í”„ë ˆì„ì›Œí¬
- [HuggingFace](https://huggingface.co/) - ëª¨ë¸ í˜¸ìŠ¤íŒ…

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**ì£¼ì˜**: ì´ ì„œë²„ëŠ” ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ì™€ GPU ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ ì¶©ë¶„í•œ í•˜ë“œì›¨ì–´ ë¦¬ì†ŒìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.
